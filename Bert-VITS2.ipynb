{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RomxmJkjnqE",
        "outputId": "6eaeb474-9664-4e7a-ef8a-40895e12a961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Dec 31 04:37:17 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU configuration\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS4NwdX8fQhg",
        "outputId": "cb58ba27-8d1b-4a77-db1f-2d0877a3cde4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title STEP 0 連接 Google Drive\n",
        "#@markdown #STEP 0\n",
        "#@markdown ##連接 Google Drive\n",
        "#@markdown ##Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu-XmSvFj1gg"
      },
      "source": [
        "#STEP 0 確認有使用GPU\n",
        "##記事本必須在GPU模式下運行，可以執行上方的nvidia-smi查看GPU是否有GPU。若没有，點擊左上角的 編輯>筆記本設定，把硬體加速器改成GPU。\n",
        "##如記事本有出問題可在以下儲存庫回報\n",
        "> https://github.com/ADT109119/Bert-VITS2-Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2PYE5UE4cCc",
        "outputId": "45f907e1-58cb-44dd-fa11-9e1b88aa09ee"
      },
      "outputs": [],
      "source": [
        "#@title STEP 1 複製儲存庫並安裝必要的函式庫\n",
        "#@markdown #STEP 1\n",
        "#@markdown ##複製儲存庫並安裝必要的函式庫\n",
        "#@markdown ##Clone repository & Install requirements lib\n",
        "#@markdown ###\n",
        "#@markdown ###選擇訓練版本\n",
        "training_mode = \"一般版本\" # @param [\"一般版本\", \"中文特化版\"]\n",
        "training_modes = [\"一般版本\", \"中文特化版\"]\n",
        "if training_mode == training_modes[0]:\n",
        "    !git clone https://github.com/fishaudio/Bert-VITS2.git\n",
        "elif training_mode == training_modes[1]:\n",
        "    !git clone https://github.com/fishaudio/Bert-VITS2.git --branch Extra-Fix\n",
        "%cd ./Bert-VITS2/\n",
        "!pip install -r requirements.txt\n",
        "!pip install pyyaml\n",
        "\n",
        "#下載 Bert 以及 wavlm 模型\n",
        "!wget https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/pytorch_model.bin?download=true -O slm/wavlm-base-plus/pytorch_model.bin\n",
        "\n",
        "if training_mode == training_modes[0]:\n",
        "    !rm -rf bert/chinese-roberta-wwm-ext-large\n",
        "    !git clone https://huggingface.co/hfl/chinese-roberta-wwm-ext-large bert/chinese-roberta-wwm-ext-large\n",
        "    !rm -rf bert/deberta-v2-large-japanese-char-wwm\n",
        "    !git clone https://huggingface.co/ku-nlp/deberta-v2-large-japanese-char-wwm bert/deberta-v2-large-japanese-char-wwm\n",
        "    !rm -rf bert/deberta-v3-large\n",
        "    !git clone https://huggingface.co/microsoft/deberta-v3-large bert/deberta-v3-large\n",
        "\n",
        "elif training_mode == training_modes[1]:\n",
        "    !rm -rf bert/Erlangshen-MegatronBert-1.3B-Chinese\n",
        "    !git clone https://huggingface.co/IDEA-CCNL/Erlangshen-MegatronBert-1.3B bert/Erlangshen-MegatronBert-1.3B-Chinese\n",
        "    !rm -rf emotional/clap-htsat-fused\n",
        "    !git clone https://huggingface.co/laion/clap-htsat-fused emotional/clap-htsat-fused\n",
        "    !rm -rf emotional/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
        "    !git clone https://huggingface.co/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim emotional/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
        "    !wget https://huggingface.co/ADT109119/G2PWModel-v2-onnx/resolve/main/g2pw.onnx?download=true -O g2pW/g2pW.onnx\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ5CZVxxRlpx"
      },
      "source": [
        "# Bert-VITS2 数据预处理\n",
        "\n",
        "数据准备：\n",
        "将数据放置在 data 文件夹下，按照如下结构组织：\n",
        "\n",
        "```\n",
        "├── data\n",
        "│   ├── {你的数据集名称}\n",
        "│   │   ├── esd.list\n",
        "│   │   ├── raw\n",
        "│   │   │   ├── ****.wav\n",
        "│   │   │   ├── ****.wav\n",
        "│   │   │   ├── ...\n",
        "```\n",
        "\n",
        "其中，`raw` 文件夹下保存所有的音频文件，`esd.list` 文件为标签文本，格式为\n",
        "\n",
        "```\n",
        "****.wav|{说话人名}|{语言 ID}|{标签文本}\\n\n",
        "```\n",
        "\n",
        "例如：\n",
        "```\n",
        "vo_ABDLQ001_1_paimon_02.wav|派蒙|ZH|没什么没什么，只是平时他总是站在这里，有点奇怪而已\n",
        "noa_501_0001.wav|NOA|JP|そうだね、油断しないのはとても大事なことだと思う\\n\"\n",
        "Albedo_vo_ABDLQ002_4_albedo_01.wav|Albedo|EN|Who are you? Why did you alarm them?\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edd8YOVJr7hh",
        "outputId": "485c2812-2984-4377-e108-10cdf7f5d9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43NK2XSH8cgN"
      },
      "outputs": [],
      "source": [
        "#@title STEP 2-1 生成上傳按鈕載入資料集\n",
        "#@markdown #STEP 2-1\n",
        "#@markdown ##生成上傳按鈕載入資料集\n",
        "#@markdown ##Upload Dataset\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "uploaded = files.upload()\n",
        "basepath = os.getcwd()\n",
        "upload_path = \"./\"\n",
        "for filename in uploaded.keys():\n",
        "  shutil.move(os.path.join(basepath, filename), os.path.join(upload_path, \"data.zip\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tXYzufRyIsy"
      },
      "outputs": [],
      "source": [
        "#@title STEP 2-2 從Google Drive載入資料集\n",
        "#@markdown #STEP 2-2\n",
        "#@markdown ##載入資料集\n",
        "#@markdown ##Upload Dataset from Google Drive\n",
        "\n",
        "#@markdown ###資料集路徑\n",
        "data_set_zip_file = \"/content/drive/MyDrive/Bert-VITS2/data.zip\" #@param {type:\"string\"}\n",
        "\n",
        "!cp -rf {data_set_zip_file} ./data.zip\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N976Ct850V1"
      },
      "outputs": [],
      "source": [
        "#@title STEP 2-3 上傳音檔 透過Whisper生成字幕再自動切分 (因準確度關係 不建議使用)\n",
        "#@markdown #STEP 2-3\n",
        "#@markdown ##透過Whisper生成字幕再自動切分\n",
        "#@markdown ##(因準確度關係 不建議使用)\n",
        "#@markdown ##Upload audios and generate subtitle by OpenAI Whisper to split audios\n",
        "#@markdown ##(Not recomand)\n",
        "#@markdown ##音檔請依照 `{說話者名稱}_{語言}_{隨便的編號}` 格式\n",
        "\n",
        "!apt install ffmpeg\n",
        "\n",
        "!git clone https://github.com/ADT109119/Bert-VITS2-colab.git upload_audios\n",
        "\n",
        "!mkdir upload_audios\n",
        "!mkdir upload_audios/audio\n",
        "!mkdir upload_audios/srt\n",
        "\n",
        "upload_from_google_drive = True # @param {type:\"boolean\"}\n",
        "\n",
        "if upload_from_google_drive:\n",
        "  data_folder_path = \"/content/drive/MyDrive/Bert-VITS2/audio\" #@param {type:\"string\"}\n",
        "  !cp -rf {data_folder_path}/* ./upload_audios/audio\n",
        "else:\n",
        "  from google.colab import files\n",
        "  import shutil\n",
        "  import os\n",
        "  uploaded = files.upload()\n",
        "  basepath = os.getcwd()\n",
        "  upload_path = \"./upload_audios/audio\"\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(os.path.join(basepath, filename), os.path.join(upload_path, filename))\n",
        "\n",
        "!pip install openai-whisper\n",
        "import glob\n",
        "\n",
        "file_list = glob.glob(\"upload_audios/audio/*.wav\")\n",
        "for path in file_list:\n",
        "  !whisper {path} --model large-v3 --output_dir \"./upload_audios/srt\"\n",
        "\n",
        "!python ./upload_audios/processing.py\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_folder_with_file(folder_path, file_path, output_path):\n",
        "    with zipfile.ZipFile(output_path, 'w') as zip_file:\n",
        "        for foldername, subfolders, filenames in os.walk(folder_path):\n",
        "            for filename in filenames:\n",
        "                file_path_in_folder = os.path.join(foldername, filename)\n",
        "                zip_file.write(file_path_in_folder, os.path.relpath(file_path_in_folder, os.path.dirname(folder_path)))\n",
        "\n",
        "        zip_file.write(file_path, os.path.basename(file_path))\n",
        "\n",
        "zip_folder_with_file('./upload_audios/raw', './upload_audios/esd.list', './data.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF34yVSD-b0-"
      },
      "outputs": [],
      "source": [
        "#@title STEP 2.1 解壓縮資料集\n",
        "#@markdown #STEP 2.1\n",
        "#@markdown ##解壓縮資料集\n",
        "#@markdown ##Unzip Data\n",
        "\n",
        "#@markdown ###資料集名稱\n",
        "!mkdir data\n",
        "\n",
        "data_dir = \"dataset\" #@param {type:\"string\"}\n",
        "!unzip ./data.zip -d ./data/{data_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiFJX0-d6thC"
      },
      "outputs": [],
      "source": [
        "#@title STEP 2.5 處理資料\n",
        "#@markdown #STEP 2.5\n",
        "#@markdown ##處理資料\n",
        "#@markdown ##Process Data\n",
        "from webui_preprocess import generate_config, resample, preprocess_text, bert_gen\n",
        "batch_size = 8 # @param {type:\"integer\"}\n",
        "print(generate_config(data_dir, batch_size))\n",
        "print(resample(data_dir))\n",
        "print(preprocess_text(data_dir))\n",
        "\n",
        "#修改 config.yml\n",
        "import yaml\n",
        "def load_yaml(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
        "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "    return data\n",
        "def save_yaml(data, file_path):\n",
        "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
        "        yaml.dump(data, file, default_flow_style=False)\n",
        "# 載入 YAML 檔案\n",
        "yaml_file_path = 'config.yml'\n",
        "yaml_data = load_yaml(yaml_file_path)\n",
        "# 修改 YAML 中的內容\n",
        "yaml_data['dataset_path'] = f\"data/{data_dir}\"\n",
        "yaml_data['train_ms']['config_path'] = \"configs/config.json\"\n",
        "if training_mode == training_modes[1]:\n",
        "    yaml_data['bert_gen']['num_processes'] = 1\n",
        "\n",
        "# 儲存修改後的 YAML 檔案\n",
        "save_yaml(yaml_data, yaml_file_path)\n",
        "print(bert_gen(data_dir))\n",
        "\n",
        "if training_mode == training_modes[1]:\n",
        "    !python clap_gen.py --config data/{data_dir}/configs/config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgvT1jqef9Xy"
      },
      "outputs": [],
      "source": [
        "#@title STEP 2.6 自動儲存步數修改\n",
        "#@markdown #STEP 2.6\n",
        "#@markdown ##自動儲存步數修改\n",
        "\n",
        "#@markdown ###每隔n步自動儲存\n",
        "save_step = 200 # @param {type:\"integer\"}\n",
        "\n",
        "import json\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def save_json(data, file_path):\n",
        "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
        "        json.dump(data, file, indent=2)\n",
        "\n",
        "# 載入 JSON 檔案\n",
        "json_file_path = f\"data/{data_dir}/configs/config.json\"\n",
        "json_data = load_json(json_file_path)\n",
        "\n",
        "# 修改 JSON 中的內容\n",
        "json_data['train']['log_interval'] = save_step\n",
        "json_data['train']['eval_interval'] = save_step\n",
        "\n",
        "# 儲存修改後的 JSON 檔案\n",
        "save_json(json_data, json_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_vf9UZuRUPD"
      },
      "source": [
        "# STEP 3 載入模型\n",
        "## 3-1、3-2 則一"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfCOo-7YTCOK"
      },
      "outputs": [],
      "source": [
        "#@title STEP 3-1 下載預訓練模型\n",
        "if training_mode == training_modes[0]:\n",
        "    !git clone https://huggingface.co/OedoSoldier/Bert-VITS2-2.3 data/{data_dir}/models\n",
        "elif training_mode == training_modes[1]:\n",
        "    !git clone https://huggingface.co/v3ucn/Bert-vits2-Extra-Pretrained_models data/{data_dir}/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sKnejk_e2V6"
      },
      "outputs": [],
      "source": [
        "#@title STEP 3-2 載入上次訓練到一半 儲存在 Google Drive 的模型\n",
        "!cp -f ../drive/MyDrive/Bert-VITS2/models/* data/{data_dir}/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HF1Uwy0UUZA"
      },
      "source": [
        "#STEP 4 開始訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EMbEm9Fy0DhA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TENSORBOARD_BINARY'] = '/usr/local/bin/tensorboard'\n",
        "%reload_ext tensorboard\n",
        "model_dir = f\"./data/{data_dir}/models\"\n",
        "%tensorboard --logdir $model_dir\n",
        "\n",
        "!torchrun --nproc_per_node=1 train_ms.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WP5QJC7Q0eS"
      },
      "source": [
        "#STEP 5 推理測試\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBIfMtsH74u2"
      },
      "outputs": [],
      "source": [
        "#@title STEP 5 推理測試\n",
        "#@markdown #STEP 5\n",
        "#@markdown ##推理測試\n",
        "\n",
        "#@markdown ###\n",
        "#@markdown ###推理所使用的模型步數\n",
        "model_step = 2000 # @param {type:\"integer\"}\n",
        "import yaml\n",
        "def load_yaml(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "    return data\n",
        "def save_yaml(data, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        yaml.dump(data, file, default_flow_style=False)\n",
        "# 載入 YAML 檔案\n",
        "yaml_file_path = 'config.yml'\n",
        "yaml_data = load_yaml(yaml_file_path)\n",
        "# 修改 YAML 中的內容\n",
        "yaml_data['dataset_path'] = f\"data/{data_dir}\"\n",
        "yaml_data['webui']['share'] = \"true\"\n",
        "yaml_data['webui']['model'] = f\"models/G_{model_step}.pth\"\n",
        "yaml_data['webui']['config_path'] = \"configs/config.json\"\n",
        "# 儲存修改後的 YAML 檔案\n",
        "save_yaml(yaml_data, yaml_file_path)\n",
        "!torchrun --nproc_per_node=1 webui.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7VH8k-s0G71"
      },
      "source": [
        "#STEP 6 保存到Google Drive(自選)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2StL2Wqt0MAt"
      },
      "outputs": [],
      "source": [
        "#@title STEP 6.1 連接Google Drive\n",
        "#@markdown ##如果前面連接過了 這邊就不用再連一次\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72nLh_L50g74"
      },
      "outputs": [],
      "source": [
        "#@title STEP 6.2 複製檔案到Google Drive\n",
        "#@markdown ###模型儲存路徑\n",
        "Google_Drive_Folder = \"/content/drive/MyDrive/Bert-VITS2\" #@param {type:\"string\"}\n",
        "#@markdown ###儲存模型步數\n",
        "steps = 2000 # @param {type:\"integer\"}\n",
        "!mkdir {Google_Drive_Folder}/models\n",
        "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/G_{steps}.pth {Google_Drive_Folder}/models/\n",
        "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/D_{steps}.pth {Google_Drive_Folder}/models/\n",
        "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/WD_{steps}.pth {Google_Drive_Folder}/models/\n",
        "!cp -rf /content/Bert-VITS2/data/{data_dir}/models/DUR_{steps}.pth {Google_Drive_Folder}/models/\n",
        "!cp -rf /content/Bert-VITS2/data/{data_dir}/configs {Google_Drive_Folder}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXOlMMjr_7tE"
      },
      "source": [
        "#STEP 7 下載模型(自選)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5LOtjRo_pls"
      },
      "outputs": [],
      "source": [
        "#@markdown ###下載模型步數\n",
        "from google.colab import files\n",
        "steps = 2000 # @param {type:\"integer\"}\n",
        "files.download(f\"./data/{data_dir}/models/G_{steps}.pth\")\n",
        "files.download(f\"./data/{data_dir}/models/D_{steps}.pth\")\n",
        "files.download(f\"./data/{data_dir}/models/WD_{steps}.pth\")\n",
        "files.download(f\"./data/{data_dir}/models/DUR_{steps}.pth\")\n",
        "files.download(f\"./data/{data_dir}/configs/config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#STEP 8 一鍵部署到 HuggingFace 上 (尚不支持中文特化版)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title STEP 8.1 使用API Token登入\n",
        "#@markdown #STEP 8.1\n",
        "#@markdown ##執行本儲存格後填入 Access Token(需要有 Write 權限)，然後按下登入\n",
        "#@markdown ##After runing this cell, fill in the Access Token (Write permission is required), and then click Login\n",
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title STEP 8.2 上傳模型\n",
        "#@markdown #STEP 8.2\n",
        "#@markdown ##在此儲存格填入 `HF 儲存庫 ID`、`欲使用的模型 Step`、`作者`......等資訊\n",
        "#@markdown ##執行後便可創建 Space\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "#複製模板\n",
        "!rm -rf Bert-VITS2-Docker-template\n",
        "if training_mode == training_modes[0]:\n",
        "    !git clone https://github.com/ADT109119/Bert-VITS2-Docker-template.git\n",
        "elif training_mode == training_modes[1]:\n",
        "    !git clone https://github.com/ADT109119/Bert-VITS2-Docker-template.git --branch Chinese\n",
        "\n",
        "#@markdown ###\n",
        "#@markdown ###使用的模型步數:\n",
        "model_step = 2000 # @param {type:\"integer\"}\n",
        "import yaml\n",
        "def load_yaml(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "    return data\n",
        "def save_yaml(data, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "yaml_data = load_yaml(\"Bert-VITS2-Docker-template/config.yml\")\n",
        "yaml_data['dataset_path'] = f\"Data/{data_dir}\"\n",
        "yaml_data['webui']['model'] = f\"models/G_{model_step}.pth\"\n",
        "save_yaml(yaml_data, \"Bert-VITS2-Docker-template/config.yml\")\n",
        "\n",
        "#@markdown ###儲存庫ID:\n",
        "repo_id_ = \"username/Bert-VITS2\" #@param {type:\"string\"}\n",
        "#@markdown ###Space 名稱:\n",
        "space_name = \"Bert-VITS2\" #@param {type:\"string\"}\n",
        "#@markdown ###作者:\n",
        "space_author = \"作者\" #@param {type:\"string\"}\n",
        "#@markdown ###聲音歸屬:\n",
        "voice_ = \"聲音屬於 xxx\" #@param {type:\"string\"}\n",
        "#@markdown ###是否為私人Space (打勾為不公開):\n",
        "private_ = True # @param {type:\"boolean\"}\n",
        "\n",
        "import json\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def save_json(data, file_path):\n",
        "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
        "        json.dump(data, file, indent=2)\n",
        "\n",
        "json_data = load_json(\"Bert-VITS2-Docker-template/author_and_voice_data.json\")\n",
        "json_data['author'] = space_author\n",
        "json_data['voice'] = voice_\n",
        "save_json(json_data, \"Bert-VITS2-Docker-template/author_and_voice_data.json\")\n",
        "\n",
        "#複製模型與Config\n",
        "!mkdir Bert-VITS2-Docker-template/Data/{data_dir}\n",
        "!mkdir Bert-VITS2-Docker-template/Data/{data_dir}/models\n",
        "!cp data/{data_dir}/models/G_{model_step}.pth Bert-VITS2-Docker-template/Data/{data_dir}/models\n",
        "!cp data/{data_dir}/configs/config.json Bert-VITS2-Docker-template/Data/{data_dir}\n",
        "\n",
        "!rm -rf Bert-VITS2-Docker-template/.git\n",
        "\n",
        "with open('Bert-VITS2-Docker-template/README.md', 'r+', encoding='utf-8') as fr:\n",
        "  content = fr.read()\n",
        "  content = content.replace(\"title: Bert VITS2 Docker Template\", f\"title: {space_name}\")\n",
        "  fr.seek(0)\n",
        "  fr.write(content)\n",
        "  fr.truncate()\n",
        "\n",
        "api.create_repo(repo_id_, private=private_, repo_type=\"space\", space_sdk=\"docker\")\n",
        "api.upload_folder(\n",
        "    repo_type=\"space\",\n",
        "    folder_path='Bert-VITS2-Docker-template/',\n",
        "    repo_id=repo_id_,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
